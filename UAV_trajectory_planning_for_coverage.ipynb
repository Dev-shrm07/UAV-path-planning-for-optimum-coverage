{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2L0RQvnX5iWH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "#replay buffer class\n",
        "\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, mem_size, input_shape, num_actions):\n",
        "        self.mem_size = mem_size\n",
        "        self.mem_cntr =  0\n",
        "        self.state_memory = np.zeros((mem_size, input_shape))\n",
        "        self.new_state_memory = np.zeros((mem_size, input_shape))\n",
        "        self.action_memory = np.zeros((mem_size, num_actions))\n",
        "        self.reward_memory = np.zeros((mem_size))\n",
        "        self.terminal_memory = np.zeros(mem_size, dtype = np.bool)\n",
        "    \n",
        "    def store_transition(self, state, action, reward, new_state, done):\n",
        "        index = self.mem_cntr%self.mem_size\n",
        "        self.state_memory[index] = state\n",
        "        self.action_memory[index] = action\n",
        "        self.new_state_memory[index] = new_state\n",
        "        self.reward_memory[index] = reward\n",
        "        self.terminal_memory[index] = done\n",
        "\n",
        "        self.mem_cntr += 1\n",
        "    \n",
        "    def sample_buffer(self, batch_size):\n",
        "        max_mem = min(self.mem_cntr, self.mem_size)\n",
        "\n",
        "        batch = np.random.choice(max_mem, batch_size, replace = False)\n",
        "        states = self.state_memory[batch]\n",
        "        states_ = self.new_state_memory[batch]\n",
        "        actions = self.action_memory[batch]\n",
        "        rewards = self.reward_memory[batch]\n",
        "        dones = self.terminal_memory[batch]\n",
        "\n",
        "        return states, states_, actions, rewards, dones\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from keras.layers import Dense\n",
        "\n",
        "\n",
        "#critic network\n",
        "\n",
        "class Critic(keras.Model):\n",
        "    def __init__(self,  name, hl1_dims, hl2_dims):\n",
        "        super(Critic, self).__init__()\n",
        "        self.hl1_dims = hl1_dims\n",
        "        self.hl2_dims = hl2_dims\n",
        "        self._name = name\n",
        "\n",
        "        self.hl1 = Dense(self.hl1_dims, activation = 'relu')\n",
        "        self.hl2 = Dense(self.hl2_dims, activation = 'relu')\n",
        "        self.q = Dense(1, activation = None)\n",
        "\n",
        "    def call(self, state, action, training=None):\n",
        "        \n",
        "        action_value = self.hl1(tf.concat([state, action], axis = 1))\n",
        "        action_value = self.hl2(action_value)\n",
        "        q = self.q(action_value)\n",
        "\n",
        "        return q\n",
        "\n",
        "\n",
        "#actor network\n",
        "\n",
        "\n",
        "class Actor(keras.Model):\n",
        "    def __init__(self, name, hl1_dims, hl2_dims, n_actions):\n",
        "        super(Actor, self).__init__()\n",
        "        self.hl1_dims = hl1_dims\n",
        "        self.hl2_dims = hl2_dims\n",
        "        self._name = name\n",
        "        self.n_actions = n_actions\n",
        "\n",
        "        self.hl1 = Dense(self.hl1_dims, activation = 'relu')\n",
        "        self.hl2 = Dense(self.hl2_dims, activation = 'relu')\n",
        "        self.action = Dense(n_actions, activation = 'tanh')\n",
        "    \n",
        "    def call(self, state, training = None):\n",
        "        a1 = self.hl1(state)\n",
        "        a2 = self.hl2(a1)\n",
        "        ac = self.action(a2)\n",
        "\n",
        "        return ac\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k6itUC9e6jNx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#DDPG agent class\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, input_dims, n_actions, alpha = 0.001, beta = 0.002, gama = 0.99, max_size = 1000000, tau = 0.005, hl1_dims = 400, hl2_dims = 300,env = None, batch_size = 64):\n",
        "        self.gama = gama \n",
        "        self.tau = tau\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.batch_size = batch_size\n",
        "        self.n_actions = n_actions\n",
        "        self.buffer = ReplayBuffer(max_size, input_dims, n_actions)\n",
        "        self.max_action = 1;\n",
        "        self.min_action = -1;\n",
        "       \n",
        "        self.actor = Actor(name='actor', hl1_dims=hl1_dims, hl2_dims=hl2_dims, n_actions=n_actions)\n",
        "        \n",
        "        self.target_actor = Actor(name='target_actor', hl1_dims=hl1_dims, hl2_dims=hl2_dims, n_actions=n_actions)\n",
        "        \n",
        "        self.critic = Critic(name='critic', hl1_dims=hl1_dims, hl2_dims=hl2_dims)\n",
        "        \n",
        "        self.target_critic = Critic(name='target_critic', hl1_dims=hl1_dims, hl2_dims=hl2_dims)\n",
        "\n",
        "        \n",
        "        self.actor.compile(optimizer = Adam(learning_rate = alpha))\n",
        "        self.target_actor.compile(optimizer = Adam(learning_rate = alpha))\n",
        "        self.critic.compile(optimizer = Adam(learning_rate = beta))\n",
        "        self.target_critic.compile(optimizer = Adam(learning_rate = beta))\n",
        "        self.critic_grad = Adam(learning_rate = alpha)\n",
        "\n",
        "\n",
        "        self.update(tau = 1)\n",
        "\n",
        "    #applying soft updates on target actor and target critic\n",
        "    \n",
        "    def update(self, tau = None):\n",
        "        if tau is None:\n",
        "            tau = self.tau\n",
        "        \n",
        "        weights = []\n",
        "        targets = self.target_actor.weights\n",
        "        for i, weight in enumerate(self.actor.weights):\n",
        "            weights.append(weight*tau + targets[i]*(1-tau))\n",
        "        \n",
        "        self.target_actor.set_weights(weights)\n",
        "\n",
        "        weights = []\n",
        "        targets = self.target_critic.weights\n",
        "        for i, weight in enumerate(self.critic.weights):\n",
        "            weights.append(weight*tau + targets[i]*(1-tau))\n",
        "        \n",
        "        self.target_critic.set_weights(weights)\n",
        "    \n",
        "    def remember(self, state, state_, action, reward, done):\n",
        "        self.buffer.store_transition(state=state, action=action, reward=reward, new_state=state_, done=done)\n",
        "    \n",
        "\n",
        "    \n",
        "    def choose_action(self, state, evaluate = False):\n",
        "\n",
        "        input_tensor = tf.convert_to_tensor(state)\n",
        "        tf_state = tf.expand_dims(input_tensor, 0)\n",
        "        actions = self.actor(tf_state)\n",
        "        actions += tf.random.normal(shape = [self.n_actions], mean = 0.0, stddev = 0.1)\n",
        "        actions = tf.clip_by_value(actions, self.min_action, self.max_action)\n",
        "        return actions[0]\n",
        "\n",
        "\n",
        "    #applying graidents on the actor and critic network according to their loss fucntions\n",
        "    \n",
        "    def learn(self):\n",
        "        if(self.buffer.mem_cntr<self.batch_size):\n",
        "            return\n",
        "        \n",
        "        states, states_, actions, rewards, dones = self.buffer.sample_buffer(self.batch_size)\n",
        "\n",
        "        state = tf.convert_to_tensor(states, dtype = tf.float32)\n",
        "        state_ = tf.convert_to_tensor(states_, dtype = tf.float32)\n",
        "        action = tf.convert_to_tensor(actions, dtype = tf.float32)\n",
        "        reward = tf.convert_to_tensor(rewards, dtype = tf.float32)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            target_actions = self.target_actor(state_)\n",
        "            delta = tf.squeeze(self.target_critic(\n",
        "                state_, target_actions), 1)\n",
        "            y = reward + self.gama * delta*(1-dones)\n",
        "            critic_value = tf.squeeze(self.critic(state, action), 1)\n",
        "            critic_loss = keras.losses.MSE(y, critic_value)\n",
        "\n",
        "        critic_grad = tape.gradient(critic_loss, self.critic.trainable_variables)\n",
        "        self.critic.optimizer.apply_gradients(\n",
        "            zip(critic_grad, self.critic.trainable_variables)\n",
        "\n",
        "        )\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            actions = self.actor(state)\n",
        "            cv = -self.critic(state, actions)\n",
        "            actor_loss = tf.math.reduce_mean(cv)\n",
        "\n",
        "        actor_grad = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
        "        self.actor.optimizer.apply_gradients(\n",
        "            zip(actor_grad, self.actor.trainable_variables)\n",
        "        )\n",
        "\n",
        "        self.update(self.tau)\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \n"
      ],
      "metadata": {
        "id": "IVLGyTMV7VGl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "import gym\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def create_UE_cluster(x1, y1, x2, y2):\n",
        "  X = []\n",
        "  Y = []\n",
        "  while(len(X)<10):\n",
        "    cord_x = round(random.uniform(x1,x2),2)\n",
        "    if(cord_x not in X):\n",
        "      X.append(cord_x)\n",
        "  while(len(Y)<10):\n",
        "    cord_y = round(random.uniform(y1,y2),2)\n",
        "    if(cord_y not in Y):\n",
        "      Y.append(cord_y)\n",
        "  k = []\n",
        "  i = 0\n",
        "  while(i<10):\n",
        "      k.append([X[i],Y[i]])\n",
        "      i += 1\n",
        "        \n",
        "  return k\n",
        "\n",
        "ue_cluster_1 = create_UE_cluster(400, 450, 470, 520)\n",
        "\n",
        "\n",
        "#custum environment\n",
        "\n",
        "\n",
        "class UAVENV():\n",
        "  def __init__(self, c1):\n",
        "    self.cluster1 = c1\n",
        "    self.cluster = self.clustercentre(c1)\n",
        "\n",
        "\n",
        "  def step(self, action):\n",
        "    #action = action[0]\n",
        "    d = (action[0]/2+0.5)*100\n",
        "    theta = (action[1]/2+0.5)*299\n",
        "    dummy = self.state\n",
        "    dummy[0] += d*math.cos(theta)\n",
        "    dummy[1] += d*math.sin(theta)\n",
        "\n",
        "    if(dummy[0]<=600 and dummy[1]<=600):\n",
        "      self.state = dummy\n",
        "    \n",
        "    dis = self.dist(self.state, self.cluster)\n",
        "    done = False\n",
        "    if(dis<=50):\n",
        "      done = True\n",
        "\n",
        "    return self.state, -1*dis, done\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def dist(self, pos1, pos2):\n",
        "    return ((pos1[0]-pos2[0])**2+(pos1[1]-pos2[1])**2)**0.5\n",
        "\n",
        "  def clustercentre(self, c):\n",
        "   x = np.array(c)\n",
        "   km = KMeans(n_clusters=1).fit(x)\n",
        "   return km.cluster_centers_[0]\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  def reset(self):\n",
        "    \n",
        "    \n",
        "    \n",
        "    u1 = np.array([200, 200], dtype = np.float32)\n",
        "    self.state = u1\n",
        "    return self.state\n",
        "    \n",
        "\n",
        "\n",
        "  \n",
        "  def render(self):\n",
        "    fig, ax = plt.subplots()\n",
        "    X = []\n",
        "    Y = []\n",
        "    for i in range(0,10):\n",
        "        X.append(self.cluster1[i][0])\n",
        "        Y.append(self.cluster1[i][1])\n",
        "\n",
        "    ax.set_xlim([0,600])\n",
        "    ax.set_ylim([0,600])\n",
        "    ax.plot(np.array(X),np.array(Y),'ro')\n",
        "    uavcord1 = (self.state[0],self.state[1])\n",
        "    ax.scatter(uavcord1[0], uavcord1[1], marker = \"X\", s= 200)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "6-IzKiCuDQva"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    env = UAVENV(ue_cluster_1)\n",
        "    agent = Agent(input_dims=2, n_actions=2, env = env)\n",
        "\n",
        "    score_history = []\n",
        "    avgscore = []\n",
        "    \n",
        "    \n",
        "    for i in range(50):\n",
        "        obs = env.reset()\n",
        "        done = False\n",
        "        score = 0\n",
        "        t = 0\n",
        "        while (not done and t<100):\n",
        "            action = agent.choose_action(obs)\n",
        "            obs_, reward, done = env.step(action)\n",
        "            score += reward\n",
        "            agent.remember(obs, obs_, action, reward, done)\n",
        "            agent.learn()\n",
        "            t += 1\n",
        "            obs = obs_\n",
        "        \n",
        "        score_history.append(score)\n",
        "        avg_score = np.mean(score_history[-100:])\n",
        "        avgscore.append(avg_score)\n",
        "\n",
        "\n",
        "        print('episode', i, 'score:', avg_score)\n",
        "        \n",
        "  \n",
        "\n",
        "    plt.plot(avgscore)\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Avg. Epsiodic Reward\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P5v-FXbF9cU2",
        "outputId": "7fcb0059-60b9-4796-e70e-4d5d0f044f3f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-a009ebd464a7>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  self.terminal_memory = np.zeros(mem_size, dtype = np.bool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode 0 score: -48708.51859542928\n",
            "episode 1 score: -41402.174742074836\n",
            "episode 2 score: -39074.47793885662\n",
            "episode 3 score: -38080.719799444705\n",
            "episode 4 score: -36698.73900949861\n",
            "episode 5 score: -36023.503456419036\n",
            "episode 6 score: -35623.446737854676\n",
            "episode 7 score: -35501.62717457302\n",
            "episode 8 score: -35110.42777899654\n",
            "episode 9 score: -34837.17217569215\n",
            "episode 10 score: -34732.190535552865\n",
            "episode 11 score: -34602.6110396331\n",
            "episode 12 score: -34334.53420954136\n",
            "episode 13 score: -34268.18640415374\n",
            "episode 14 score: -34251.90258034594\n",
            "episode 15 score: -34148.233627958965\n",
            "episode 16 score: -34124.38090633832\n",
            "episode 17 score: -34003.898023402595\n",
            "episode 18 score: -33927.22547443415\n",
            "episode 19 score: -33928.18208336678\n",
            "episode 20 score: -34000.50737719675\n",
            "episode 21 score: -34020.161095591415\n",
            "episode 22 score: -33973.65944537427\n",
            "episode 23 score: -33895.90232255897\n",
            "episode 24 score: -33957.773077930084\n",
            "episode 25 score: -33886.57362666566\n",
            "episode 26 score: -33868.077083010394\n",
            "episode 27 score: -33870.4047161662\n",
            "episode 28 score: -33908.75012710925\n",
            "episode 29 score: -34049.398641286614\n",
            "episode 30 score: -34042.91275786624\n",
            "episode 31 score: -34067.89807162987\n",
            "episode 32 score: -34057.69812840038\n",
            "episode 33 score: -34064.36306996224\n",
            "episode 34 score: -34097.386821809385\n",
            "episode 35 score: -34164.3906524391\n",
            "episode 36 score: -34146.11018455985\n",
            "episode 37 score: -34112.05145227602\n",
            "episode 38 score: -34121.59839119072\n",
            "episode 39 score: -34106.89973851385\n",
            "episode 40 score: -34074.079658450275\n",
            "episode 41 score: -34137.107575499336\n",
            "episode 42 score: -34082.70134309062\n",
            "episode 43 score: -34105.84461036316\n",
            "episode 44 score: -34094.44681583602\n",
            "episode 45 score: -34109.30707767036\n",
            "episode 46 score: -34104.12778399153\n",
            "episode 47 score: -34146.2101417748\n",
            "episode 48 score: -34132.43022406441\n",
            "episode 49 score: -34097.91741488634\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}